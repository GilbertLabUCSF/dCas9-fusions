#!/usr/bin/env python3

import argparse
import logging
import os
import shutil
import sys

from pathlib import Path

import tqdm

import knock_knock.experiment
import knock_knock.parallel

import dCas9_fusions
import dCas9_fusions.experiment

def setup(args):
    package_dir = Path(os.path.realpath(dCas9_fusions.__file__)).parent

    src = package_dir / 'targets'
    dest = args.base_dir / 'targets'

    if dest.exists():
        print(f'Can\'t install to {args.base_dir}, {dest} already exists')
        sys.exit(1)

    shutil.copytree(str(src), str(dest))

    logging.info(f'Library annotations installed in {args.base_dir}')

def parallel(args):
    logger = logging.getLogger(__name__)
    logger.propagate = False
    logger.setLevel(logging.DEBUG)
    stream_handler = logging.StreamHandler()
    formatter = logging.Formatter(fmt='%(asctime)s: %(message)s',
                                  datefmt='%y-%m-%d %H:%M:%S',
                                 )
    stream_handler.setFormatter(formatter)
    stream_handler.setLevel(logging.DEBUG)
    logger.addHandler(stream_handler)

    exps = dCas9_fusions.experiment.get_all_experiments(args.base_dir)

    def process_stage(stage):
        with knock_knock.parallel.PoolWithLoggerThread(args.max_procs, logger) as process_pool:
            arg_tuples = []

            for _, exp in exps.items():
                if not args.batch or exp.batch == args.batch:
                    arg_tuple = (exp.base_dir, exp.batch, exp.sample_name, stage)
                    arg_tuples.append(arg_tuple)

            process_pool.starmap(dCas9_fusions.experiment.process_experiment_stage, arg_tuples)

    stages = args.stages.split(',')
    for stage in stages:
        process_stage(stage)

def process(args):
    stages = args.stages.split(',')

    for stage in stages:
        dCas9_fusions.experiment.process_experiment_stage(args.base_dir,
                                                          args.batch_name,
                                                          args.sample_name,
                                                          stage,
                                                         )

if __name__ == '__main__':
    logging.basicConfig(format='%(asctime)s: %(message)s',
                        datefmt='%y-%m-%d %H:%M:%S',
                        level=logging.INFO,
                       )

    parser = argparse.ArgumentParser(prog='count_domains')

    subparsers = parser.add_subparsers(dest='subcommand', title='subcommands')
    subparsers.required = True

    def add_project_directory_arg(parser):
        parser.add_argument('base_dir', type=Path, help='the base directory to store input data, reference annotations, and analysis output for a project')

    parser_setup = subparsers.add_parser('setup', help='set up annotations')
    add_project_directory_arg(parser_setup)
    parser_setup.set_defaults(func=setup)

    parser_process = subparsers.add_parser('process', help='process a single sample')
    add_project_directory_arg(parser_process)
    parser_process.add_argument('batch_name', help='batch name')
    parser_process.add_argument('sample_name', help='sample name')
    parser_process.add_argument('--stages', default='preprocess,align,categorize,visualize')
    parser_process.set_defaults(func=process)

    parser_parallel = subparsers.add_parser('parallel', help='process multiple samples in parallel')
    add_project_directory_arg(parser_parallel)
    parser_parallel.add_argument('max_procs', type=int, help='maximum number of samples to process at once')
    parser_parallel.add_argument('--batch', help='if specified, the single batch name to process; if not specified, all groups will be processed')
    parser_parallel.add_argument('--stages', default='align,categorize')
    parser_parallel.set_defaults(func=parallel)

    args = parser.parse_args()
    args.func(args)